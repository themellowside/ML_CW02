{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ML COURSEWORK PART 2</h1> <br>\n",
    "Thomas Palmer, BSC Computer Science <br>\n",
    "ID: 33346808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>PART A:</H2> <br>\n",
    "Implement logistic regression using gradient descent in Python. Once you have written the code, test your model by fitting it to the dataset given below. For this stage, do not implement regularization, cross validation, the cost function or use the sklearn library until later. The purpose of this part of the coursework is to get your logistic regression code running and to validate your model’s results with a small dataset with a known solution. Refer to the lecture slides on Logistic Regression to see the solution you should be obtaining with your model.\n",
    "\n",
    "The data to test your model on is as follows: \n",
    "X = [[0.50],[0.75],[1.00],[1.25],[1.50],[1.75],[1.75],[2.00],[2.25],[2.50],[2.75], [3.00],[3.25],[3.50],[4.00],[4.25],[4.50],[4.75],[5.00],[5.50]]\n",
    "Y = [0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "Implement the BATCH gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "-1.84928279711\n",
      "-1.8509740694\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def hThetaX(x_, thetaT):\n",
    "    return 1.0 / (1.0 + numpy.power(numpy.e, thetaT * x_))\n",
    "\n",
    "def cost(x_, y_, thetaT):\n",
    "    ##simplified cost function: -y log (htheta (x) ) - (1 - y)log(1 - htheta(x))\n",
    "    ##returns this result\n",
    "    gz = hThetaX(x_, thetaT)\n",
    "    return (-y_ * numpy.log(gz)) - ((1.0 - y_) * numpy.log(1.0 - gz))\n",
    "\n",
    "def costSum(X, Y, thetaT):\n",
    "    ##for logistic regression we need to take the sum of the costs over the total size of the data \n",
    "    m = len(X)\n",
    "    total = 0.0\n",
    "    for i in range(0, len(X)):\n",
    "        total += cost(X[i][0], Y[i], thetaT)\n",
    "    return total/m \n",
    "    \n",
    "def gradientDescent(X, Y, alpha, accuracy, thetaSize):\n",
    "    ## finds a minimum of some function J\n",
    "    ## J in this case is a cost function of logistic regression\n",
    "    ## theta : some set of parameters that are adjusted to find a minimum in the function\n",
    "    ## alpha : the learning rate. controls the rate at which gradient descent adjusts (size of step)\n",
    "    theta = 0 #numpy.zeros(1)\n",
    "    ##process : update each theta value simultaneously until convergence (a local minimum is found) \n",
    "    notConvergent = True\n",
    "    prevTheta = 1 # numpy.ones(1)\n",
    "    counter = 0\n",
    "    while notConvergent: \n",
    "        ##update each theta simultaneously such that only old values are used\n",
    "        if(abs(prevTheta - theta) < accuracy or counter > 2000):\n",
    "            notConvergent = False\n",
    "            print counter\n",
    "        else:\n",
    "            ##such and such goes here\n",
    "            prevTheta = theta\n",
    "            theta = prevTheta - (alpha * costSum(X, Y, theta))\n",
    "            counter += 1\n",
    "    print prevTheta\n",
    "    return theta      \n",
    "        \n",
    "def testLinearReg(X, Y):\n",
    "    \n",
    "    \n",
    "    \n",
    "X = [[0.50],[0.75],[1.00],[1.25],[1.50],[1.75],[1.75],[2.00],[2.25],[2.50],[2.75], [3.00],[3.25],[3.50],[4.00],[4.25],[4.50],[4.75],[5.00],[5.50]] \n",
    "Y = [0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1] \n",
    "print(gradientDescent(X, Y, 0.001, 0.0001, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 (cont).\n",
    "What are the optimal values for theta0 and theta1 learned by your implementation for logistic regression on the given data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "After how many iterations and for what value of alpha did your algorithm converge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PART B:</h2> <br>\n",
    "Compute and save the cost function for each iteration of your gradient descent algorithm. Plot the cost function over the iteration number to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "What value of alpha is too large and what happens to the cost function over the number of iterations? Plot this scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "Plot a scenario where the model seems to be converging. What does the cost function look like over the number of iterations and what is the value of alpha? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PART C: </h2> <br>\n",
    "Use the sklearn library function to validate your results. The function linear_model.SGDClassifier implements gradient descent and the function argument loss = ‘log’ applies logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "How many iterations are required for the algorithm to converge? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "Print out the model parameters learned by your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "What is your model’s prediction for 5 hours of studying? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
